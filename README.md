# Real-Time Data-Driven Decisions

This project simulates a real-time data pipeline using **Apache Spark Structured Streaming** and visualizes the processed data in a live dashboard using **Streamlit**.  
It is part of my specialization at **Mackenzie University** in the course *"Data-Driven Decision Making in Real Time"*.

The goal is to demonstrate how decisions can be guided by data â€” structured or unstructured â€” through an end-to-end pipeline from data ingestion to real-time decision support.



---

## ğŸš€ Technologies Used

- **Python 3.10+**
- **Apache Spark** (Structured Streaming)
- **Streamlit**
- **Pandas**
- **Faker** (for generating realistic fake data)
- **Docker** (optional: containerizing Spark or simulating Kafka)
- **Jupyter Notebook** (for exploratory analysis)

---

## ğŸ“ Project Structure

The project is organized as follows:

```bash
real-time-data-driven-decisions/
â”œâ”€â”€ README.md                     # This file
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ pipeline_spark_streaming.ipynb   # Jupyter Notebook for exploratory setup
â”œâ”€â”€ data/
â”‚   â””â”€â”€ simulated/                # CSV files simulating the stream
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ producer.py              # Script to simulate continuous data input
â”‚   â””â”€â”€ spark_pipeline.py        # Spark Structured Streaming main script
â”œâ”€â”€ dashboard/
â”‚   â””â”€â”€ app_streamlit.py         # Streamlit dashboard for live data visualization
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ docker-compose.yml           # Optional: to containerize Spark or simulate Kafka
â””â”€â”€ .gitignore                   # Files and folders to ignore in version control


